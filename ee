import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
import re, time

# â”€â”€ Model init â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
model_name = "unitary/toxic-bert"
tokenizer   = AutoTokenizer.from_pretrained(model_name)
model       = AutoModelForSequenceClassification.from_pretrained(model_name)
model.to("cpu")
model.eval()

labels = [
    'toxicity','severe_toxicity','obscene',
    'identity_attack','insult','threat'
]
label_map = {
    'toxicity':        'Toxic',
    'severe_toxicity': 'Highly Toxic',
    'obscene':         'Obscene',
    'identity_attack': 'Hate',
    'insult':          'Insult',
    'threat':          'Threat'
}

# â”€â”€ Scraper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def scrape_text_from_url(url: str) -> list[str]:
    opts = Options()
    opts.add_argument("--headless")
    opts.add_argument("--disable-gpu")
    # point Selenium at the APT-installed Chromium binary
    opts.binary_location = "/usr/bin/chromium"

    # point Selenium at the APT-installed ChromeDriver executable
    service = Service(executable_path="/usr/bin/chromedriver")

    driver = webdriver.Chrome(service=service, options=opts)
    driver.get(url)

    # simple scroll-to-bottom to load lazy content
    time.sleep(1)
    last_h = driver.execute_script("return document.body.scrollHeight")
    while True:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1)
        new_h = driver.execute_script("return document.body.scrollHeight")
        if new_h == last_h:
            break
        last_h = new_h

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    # strip out nav/footers/headers/scripts/styles
    for tag in soup(["script","style","nav","footer","aside","header"]):
        tag.decompose()

    blocks = soup.find_all(["article","p","li","blockquote","div"])
    texts = [b.get_text(strip=True) for b in blocks if len(b.get_text(strip=True))>30]
    return list(dict.fromkeys(texts))[:50]

# â”€â”€ Classifier & UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def batch_classify_texts(texts, threshold_text=0.5, threshold_word=0.3):
    results, word_set = [], set()
    for txt in texts:
        word_set |= set(re.findall(r"\b\w{3,}\b", txt.lower()))
    word_list = list(word_set)

    # classify single words
    W = tokenizer(word_list, return_tensors="pt", padding=True, truncation=True, max_length=16)
    with torch.no_grad():
        logits = model(**W).logits
    word_scores = torch.sigmoid(logits).cpu().numpy()

    word_map = {
        word_list[i]: [labels[j] for j,s in enumerate(row) if s>=threshold_word]
        for i,row in enumerate(word_scores)
        if any(s>=threshold_word for s in row)
    }

    # classify full text blocks
    for txt in texts:
        I = tokenizer(txt, return_tensors="pt", truncation=True, padding=True, max_length=512)
        with torch.no_grad():
            out = model(**I).logits
        scores = torch.sigmoid(out)[0].cpu().numpy()
        cats = [labels[i] for i,s in enumerate(scores) if s>=threshold_text]
        if cats:
            toks = set(re.findall(r"\b\w{3,}\b", txt.lower()))
            flagged = {w: word_map[w] for w in toks if w in word_map}
            results.append((txt, cats, flagged))
    return results

st.set_page_config(page_title="ToxiScan", layout="wide")
st.title("ðŸ›¡ï¸ ToxiScan")
st.markdown("Enter a URL, paste text, or upload a `.txt` to detect toxicity.")

opt = st.radio("Input type:", ("URL","Text","File"))
user_input = []

if opt=="URL":
    url = st.text_input("Enter URL:")
    if url:
        st.info("Scrapingâ€¦")
        try:    user_input = scrape_text_from_url(url)
        except Exception as e:
            st.error(f"Error scraping URL: {e}")

elif opt=="Text":
    txt = st.text_area("Paste text:", height=200)
    user_input = [txt] if txt else []

else:
    f = st.file_uploader("Upload .txt:", type=["txt"])
    if f:
        lines = f.read().decode("utf-8").splitlines()
        user_input = [L for L in lines if len(L.strip())>30]

if st.button("Analyze"):
    if not user_input:
        st.warning("No content provided.")
    else:
        out = batch_classify_texts(user_input)
        if not out:
            st.info("No toxic content detected.")
        else:
            for i,(blk,cats,flagged) in enumerate(out,1):
                with st.expander(f"{i}. {', '.join(label_map[c] for c in cats)}"):
                    st.write(blk)
                    if flagged:
                        st.markdown("**Flagged Words:**")
                        for w,tags in flagged.items():
                            st.markdown(f"- `{w}`: {', '.join(label_map[t] for t in tags)}")